{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet 4 : Anticiper les besoins en consommation électrique de bâtiments\n",
    "*Pierre-Eloi Ragetly*\n",
    "\n",
    "Ce projet fait parti du parcours *DataScientist* d'OpenClassrooms.\n",
    "\n",
    "L'objectif principal est de trouver un modèle permettant de prédire **les émissions de CO2 et la consommation totale d’énergie de bâtiments non destinés à l'habitation.**\n",
    "\n",
    "Pour cela nous disposons des données de la ville de Seattle pour les années 2015 et 2016. Ces données sont à récupérer sur le site kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie III : Data modeling\n",
    "\n",
    "Ce notebook a pour but de présenter le travail effectué sur la modélisation.\n",
    "\n",
    "Nous commencerons par séparer notre jeu de données en deux parties distinctes:\n",
    "- Le **training set**, qui va permettre d'entrainer les différents modèles;\n",
    "- Le **testing set**, qui permettra de déterminer la performance du modèle finale.\n",
    "\n",
    "Pour ce faire, la méthode `train_test_split()` de la classe *sklearn.model_selection* sera utilisée en réservant 20% des données pour le jeu de test.\n",
    "\n",
    "Puis les modèles les plus courants seront entraînés et comparés afin de conserver les plus prometteurs. Au préalable, *une recherche par quadrillage* sera effectuée pour automatiser le choix des *hyperparamètres*, et les variables les plus pertinentes seront sélectionnées par **RFE** (Recursive Feature Elimination).\n",
    "\n",
    "Après sélection des modèles les plus performants, nous affinerons encore les hyperparamètres à l'aide d'une *recherche aléatoire* cette fois ci, et nous en profiterons pour tester la pertinence de la variable *EnergyStarScore*.\n",
    "\n",
    "Nous analyserons enfin les erreurs des modèles afin de déterminer s'il est pertinent d'utiliser une *méthode d'ensemble*, ie. combiner plusieurs modèles pour construire un modèle plus performant.\n",
    "\n",
    "Le modèle final obtenu, nous pourrons évaluer sa performance à l'aide du jeu de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T16:06:26.614690Z",
     "start_time": "2020-06-29T16:06:25.447130Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import des librairies usuelles\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T16:06:26.636595Z",
     "start_time": "2020-06-29T16:06:26.618671Z"
    }
   },
   "outputs": [],
   "source": [
    "# Change some default parameters of matplotlib using seaborn\n",
    "plt.rcParams.update(plt.rcParamsDefault)\n",
    "plt.rcParams.update({'axes.titleweight': 'bold'})\n",
    "sns.set(style='ticks')\n",
    "current_palette = sns.color_palette('RdBu')\n",
    "sns.set_palette(current_palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T16:06:26.719607Z",
     "start_time": "2020-06-29T16:06:26.638141Z"
    }
   },
   "outputs": [],
   "source": [
    "# import data\n",
    "data = (pd.read_csv('data/data_tr.csv')\n",
    "          .set_index('OSEBuildingID')\n",
    "          .drop(columns='ENERGYSTARScore'))\n",
    "data_ess = (pd.read_csv('data/data_tr.csv')\n",
    "              .set_index('OSEBuildingID')\n",
    "              .dropna(subset=['ENERGYSTARScore']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Modéliser-la-consommation-totale-d’énergie\" data-toc-modified-id=\"Modéliser-la-consommation-totale-d’énergie-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Modéliser la consommation totale d’énergie</a></span><ul class=\"toc-item\"><li><span><a href=\"#Créer-un-jeu-de-test\" data-toc-modified-id=\"Créer-un-jeu-de-test-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Créer un jeu de test</a></span></li><li><span><a href=\"#Comparaison-des-modèles\" data-toc-modified-id=\"Comparaison-des-modèles-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Comparaison des modèles</a></span><ul class=\"toc-item\"><li><span><a href=\"#En-conservant-les-valeurs-par-défaut-des-hyperparamères\" data-toc-modified-id=\"En-conservant-les-valeurs-par-défaut-des-hyperparamères-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>En conservant les valeurs par défaut des hyperparamères</a></span></li><li><span><a href=\"#En-optimisant-les-hyperparamètres-via-des-recherches-par-grille-ou-aléatoires\" data-toc-modified-id=\"En-optimisant-les-hyperparamètres-via-des-recherches-par-grille-ou-aléatoires-1.2.2\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>En optimisant les hyperparamètres via des recherches par grille ou aléatoires</a></span></li></ul></li><li><span><a href=\"#Recherche-des-variables-les-plus-significatives\" data-toc-modified-id=\"Recherche-des-variables-les-plus-significatives-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Recherche des variables les plus significatives</a></span></li><li><span><a href=\"#Sélection-des-cinq-meilleurs-modèles\" data-toc-modified-id=\"Sélection-des-cinq-meilleurs-modèles-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Sélection des cinq meilleurs modèles</a></span></li><li><span><a href=\"#Modèle-final\" data-toc-modified-id=\"Modèle-final-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Modèle final</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modéliser la consommation totale d’énergie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour pouvoir modéliser la consommation totale en énergie il faut au préalable déterminer quelle sera notra valeur cible. Sous nous avons quatre variables potentielles :\n",
    "- SiteEnergyUse(kBtu)\n",
    "- SiteEnergyUseWN(kBtu)\n",
    "- SiteEnergyUse(kBtu)_log\n",
    "- SiteEnergyUseWN(kBtu)_log\n",
    "\n",
    "Nous avons vu lors de l'ingénierie des variable qu'il était préférable de prendre la version log pour avoir une distribution se rapprochant d'une distribution normale. On peut donc déjà écarter les deux premières.\n",
    "\n",
    "Se pose ensuite la question de savoir s'il est préférable de garder la version normalisée ou non normalisée. Pour rappel, la version normalisée et la consommation corrigée en prenant comme référence la température des trentes dernières années. Alors que la version normalisée est la consommation moyenne sur les années 2015 et 2016. Dans le contexte de réchauffement climatique, il est fort à parier que la températures des prochaines années sera plus proche de celles de 2015 et 2016 que de la température des trentes dernières années.\n",
    "\n",
    "Nous prendrons donc la version non normalisée **SiteEnergyUse(kBtu)_log**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Créer un jeu de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T16:06:26.817187Z",
     "start_time": "2020-06-29T16:06:26.721597Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data.iloc[:, :-6].values\n",
    "y = data.loc[:, 'SiteEnergyUse(kBtu)_log'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le paramètre *random_state* permet de définir *le germe* (seed) du générateur de nombre aléatoires, afin qu'il génère toujours la même suite d'indices pseudo-aléatoires."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparaison des modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour comparer les résultats obtenus avec les algorithmes de regression les plus courants (voir liste ci-dessous), nous utiliserons la librairie *Scikit-Learn* ainsi que la librairie *XGBoost*.\n",
    "- Régression Ridge\n",
    "- Régression Lasso\n",
    "- Elastic Net\n",
    "- Régression SVM linéaire\n",
    "- Régression SVM avec noyau\n",
    "- Régression kNN\n",
    "- Arbre de décision\n",
    "- Forêt aléatoire\n",
    "- Gradient Boosting\n",
    "- XG Boost\n",
    "- Perceptron multi-couches\n",
    "\n",
    "Nous utiliserons comme mesure de performance la RMSE par validation croisée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### En conservant les valeurs par défaut des hyperparamères"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T16:06:36.574409Z",
     "start_time": "2020-06-29T16:06:26.819180Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "      <th>RMSE_std</th>\n",
       "      <th>R2</th>\n",
       "      <th>R2_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>1.244510</td>\n",
       "      <td>0.751661</td>\n",
       "      <td>-0.207031</td>\n",
       "      <td>1.513799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>1.302400</td>\n",
       "      <td>0.028977</td>\n",
       "      <td>-0.002535</td>\n",
       "      <td>0.004503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNet</th>\n",
       "      <td>1.282373</td>\n",
       "      <td>0.036099</td>\n",
       "      <td>0.028226</td>\n",
       "      <td>0.015908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVR</th>\n",
       "      <td>1.297340</td>\n",
       "      <td>0.764967</td>\n",
       "      <td>-0.298505</td>\n",
       "      <td>1.574031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>0.839410</td>\n",
       "      <td>0.042076</td>\n",
       "      <td>0.582491</td>\n",
       "      <td>0.039502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>1.002512</td>\n",
       "      <td>0.043741</td>\n",
       "      <td>0.403637</td>\n",
       "      <td>0.061485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.882571</td>\n",
       "      <td>0.061143</td>\n",
       "      <td>0.537726</td>\n",
       "      <td>0.060398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.650089</td>\n",
       "      <td>0.034414</td>\n",
       "      <td>0.749625</td>\n",
       "      <td>0.024320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPRegressor</th>\n",
       "      <td>1.971323</td>\n",
       "      <td>1.171244</td>\n",
       "      <td>-2.027529</td>\n",
       "      <td>3.709032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>0.634741</td>\n",
       "      <td>0.029772</td>\n",
       "      <td>0.761478</td>\n",
       "      <td>0.019800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>0.659871</td>\n",
       "      <td>0.030612</td>\n",
       "      <td>0.742180</td>\n",
       "      <td>0.021363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               RMSE  RMSE_std        R2    R2_std\n",
       "Ridge                      1.244510  0.751661 -0.207031  1.513799\n",
       "Lasso                      1.302400  0.028977 -0.002535  0.004503\n",
       "ElasticNet                 1.282373  0.036099  0.028226  0.015908\n",
       "LinearSVR                  1.297340  0.764967 -0.298505  1.574031\n",
       "SVR                        0.839410  0.042076  0.582491  0.039502\n",
       "KNeighborsRegressor        1.002512  0.043741  0.403637  0.061485\n",
       "DecisionTreeRegressor      0.882571  0.061143  0.537726  0.060398\n",
       "RandomForestRegressor      0.650089  0.034414  0.749625  0.024320\n",
       "MLPRegressor               1.971323  1.171244 -2.027529  3.709032\n",
       "GradientBoostingRegressor  0.634741  0.029772  0.761478  0.019800\n",
       "XGBRegressor               0.659871  0.030612  0.742180  0.021363"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functions.ml_modeling import get_models\n",
    "from functions.ml_modeling import compare_models\n",
    "\n",
    "# Create models\n",
    "default_models = get_models(X_train, y_train)\n",
    "\n",
    "# Compare models\n",
    "df = compare_models(X_train, y_train, default_models)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### En optimisant les hyperparamètres via des recherches par grille ou aléatoires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T16:10:36.352383Z",
     "start_time": "2020-06-29T16:06:36.577397Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "      <th>RMSE_std</th>\n",
       "      <th>R2</th>\n",
       "      <th>R2_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.963020</td>\n",
       "      <td>0.058076</td>\n",
       "      <td>0.450730</td>\n",
       "      <td>0.057112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>1.150223</td>\n",
       "      <td>0.226098</td>\n",
       "      <td>0.196524</td>\n",
       "      <td>0.318347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNet</th>\n",
       "      <td>1.017612</td>\n",
       "      <td>0.123332</td>\n",
       "      <td>0.382556</td>\n",
       "      <td>0.140209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVR</th>\n",
       "      <td>1.223611</td>\n",
       "      <td>0.386003</td>\n",
       "      <td>0.040308</td>\n",
       "      <td>0.637085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>0.785806</td>\n",
       "      <td>0.058818</td>\n",
       "      <td>0.633079</td>\n",
       "      <td>0.053247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>0.980812</td>\n",
       "      <td>0.038988</td>\n",
       "      <td>0.430517</td>\n",
       "      <td>0.041821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.741738</td>\n",
       "      <td>0.038038</td>\n",
       "      <td>0.674374</td>\n",
       "      <td>0.027927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.645786</td>\n",
       "      <td>0.035395</td>\n",
       "      <td>0.752941</td>\n",
       "      <td>0.024605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPRegressor</th>\n",
       "      <td>2.000430</td>\n",
       "      <td>1.204692</td>\n",
       "      <td>-2.140244</td>\n",
       "      <td>3.746272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>0.635233</td>\n",
       "      <td>0.030308</td>\n",
       "      <td>0.761106</td>\n",
       "      <td>0.020088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>0.659871</td>\n",
       "      <td>0.030612</td>\n",
       "      <td>0.742180</td>\n",
       "      <td>0.021363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               RMSE  RMSE_std        R2    R2_std\n",
       "Ridge                      0.963020  0.058076  0.450730  0.057112\n",
       "Lasso                      1.150223  0.226098  0.196524  0.318347\n",
       "ElasticNet                 1.017612  0.123332  0.382556  0.140209\n",
       "LinearSVR                  1.223611  0.386003  0.040308  0.637085\n",
       "SVR                        0.785806  0.058818  0.633079  0.053247\n",
       "KNeighborsRegressor        0.980812  0.038988  0.430517  0.041821\n",
       "DecisionTreeRegressor      0.741738  0.038038  0.674374  0.027927\n",
       "RandomForestRegressor      0.645786  0.035395  0.752941  0.024605\n",
       "MLPRegressor               2.000430  1.204692 -2.140244  3.746272\n",
       "GradientBoostingRegressor  0.635233  0.030308  0.761106  0.020088\n",
       "XGBRegressor               0.659871  0.030612  0.742180  0.021363"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create models\n",
    "models = get_models(X_train, y_train, best_hparams=True)\n",
    "\n",
    "# Compare models\n",
    "df = compare_models(X_train, y_train, models)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recherche des variables les plus significatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une grande qualité des forêts aléatoires est qu'elles permettent de mesurer facilement l'importance relative des variables. C'est donc tout naturellement que nous allons les utiliser pour sélectionner les variables les plus pertinentes.\n",
    "\n",
    "Pour cela nous allons utiliser la classe **SelectFromModel** de *sklearn.feature_selection*. Cette classe permet de sélectionner toutes les variables dont l'importance (mesurée pour un modèle donné, dans notre cas il s'agira d'une forêt aléatoire) est supérieure à un certain seuil, seuil qui est donné en paramètre. Nous utiliserons une recherche par grille pour trouver le seuil optimal.\n",
    "\n",
    "Ensuite nous ne conserverons que les variables qui sont significatives et réentrainerons les modèles avec ces variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T16:17:48.571564Z",
     "start_time": "2020-06-29T16:16:28.579477Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Either fit the model before transform or set \"prefit=True\" while passing the fitted estimator to the constructor.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-34009d9ce874>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# get the mask of the features to be selected\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mforest_reg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mm\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodels\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'RandomForestRegressor'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforest_reg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mX_train_select\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mn_features_select\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Open_Classrooms\\Data_Scientist\\OC_DS_Project4\\functions\\ml_modeling.py\u001b[0m in \u001b[0;36mselect_features\u001b[1;34m(X, y, estimator, scoring)\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[0mthreshold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog10\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'selector__threshold'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mthreshold_min\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'selector'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_support\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         \u001b[1;31m# Second grid search\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pe.ragettli\\documents\\open_classrooms\\data_scientist\\oc_ds_project4\\env\\lib\\site-packages\\sklearn\\feature_selection\\_base.py\u001b[0m in \u001b[0;36mget_support\u001b[1;34m(self, indices)\u001b[0m\n\u001b[0;32m     44\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0mare\u001b[0m \u001b[0mindices\u001b[0m \u001b[0minto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minput\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0mvector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \"\"\"\n\u001b[1;32m---> 46\u001b[1;33m         \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_support_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmask\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mindices\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pe.ragettli\\documents\\open_classrooms\\data_scientist\\oc_ds_project4\\env\\lib\\site-packages\\sklearn\\feature_selection\\_from_model.py\u001b[0m in \u001b[0;36m_get_support_mask\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    173\u001b[0m             \u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m             raise ValueError('Either fit the model before transform or set'\n\u001b[0m\u001b[0;32m    176\u001b[0m                              \u001b[1;34m' \"prefit=True\" while passing the fitted'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m                              ' estimator to the constructor.')\n",
      "\u001b[1;31mValueError\u001b[0m: Either fit the model before transform or set \"prefit=True\" while passing the fitted estimator to the constructor."
     ]
    }
   ],
   "source": [
    "from functions.ml_modeling import select_features\n",
    "\n",
    "# get the mask of the features to be selected\n",
    "forest_reg = [m for m in models if type(m).__name__=='RandomForestRegressor'][0]\n",
    "mask = select_features(X_train, y_train, forest_reg)\n",
    "X_train_select = X_train[:, mask]\n",
    "n_features_select = mask.sum()\n",
    "print('{} variables ont été conservées'.format(n_features_select))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T16:11:56.697100Z",
     "start_time": "2020-06-29T16:06:25.445Z"
    }
   },
   "outputs": [],
   "source": [
    "df = compare_models(X_train, y_train, models)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T16:11:56.698095Z",
     "start_time": "2020-06-29T16:06:25.450Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create models\n",
    "models = get_models(X_train_select, y_train, best_hparams=True)\n",
    "\n",
    "# Compare models\n",
    "df = compare_models(X_train_select, y_train, models)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sélection des cinq meilleurs modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T16:11:56.700085Z",
     "start_time": "2020-06-29T16:06:25.452Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get a score based on both RMSE and R2 scores\n",
    "df['RMSE_minmax'] = (df['RMSE']-df['RMSE'].min())/(df['RMSE'].max()-df['RMSE'].min())\n",
    "df['R2_minmax'] = (df['R2']-df['R2'].min())/(df['R2'].max()-df['R2'].min())\n",
    "df['Score'] = df['R2_minmax'] - df['RMSE_minmax']\n",
    "\n",
    "# Keep the 3 models with the largest score\n",
    "best_models_name = df['Score'].nlargest(5).index\n",
    "best_models = [m for m in models if type(m).__name__ in best_models_name]\n",
    "print(\"The top three models are:\")\n",
    "for m in best_models_name:\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que nous avons réentrainé les modèles les plus prometteurs en ne conservant que les variables significatives, nous allons pouvoir obtenir le modèle finale.\n",
    "\n",
    "Pour ce modèle finale, nous allons reprendre l'astuce des modèles ensemblistes, nous allons chercher à obtenir le meilleur des modèles sélectionnés en les empilant de manière à former un nouveau modèle plus performant. Pour cela, nous utiliserons la classe **StackingRegressor** de *sklearn.ensemble*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T16:11:56.701078Z",
     "start_time": "2020-06-29T16:06:25.454Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "# Get a stacking ensemble of models\n",
    "estimators = []\n",
    "for m in best_models:\n",
    "    estimators.append((type(m).__name__, m))\n",
    "stack_reg = StackingRegressor(estimators=estimators,\n",
    "                              final_estimator=RidgeCV(alphas=np.logspace(-2, 2, 5)))\n",
    "\n",
    "# Get the results\n",
    "best_models.append(stack_reg)\n",
    "df = compare_models(X_train_select, y_train, best_models)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T16:11:56.703075Z",
     "start_time": "2020-06-29T16:06:25.456Z"
    }
   },
   "outputs": [],
   "source": [
    "models_stacking = models[:1] + models[4:6] + models[7:]\n",
    "\n",
    "# Get a stacking ensemble of models\n",
    "estimators = []\n",
    "for m in models_stacking:\n",
    "    estimators.append((type(m).__name__, m))\n",
    "stack_reg = StackingRegressor(estimators=estimators,\n",
    "                              final_estimator=RidgeCV(alphas=np.logspace(-2, 2, 5)))\n",
    "\n",
    "# Get the results\n",
    "models_stacking.append(stack_reg)\n",
    "df = compare_models(X_train_select, y_train, models_stacking)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": "1",
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "254px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
