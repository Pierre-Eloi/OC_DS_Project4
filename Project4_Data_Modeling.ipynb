{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet 4 : Anticiper les besoins en consommation électrique de bâtiments\n",
    "*Pierre-Eloi Ragetly*\n",
    "\n",
    "Ce projet fait parti du parcours *DataScientist* d'OpenClassrooms.\n",
    "\n",
    "L'objectif principal est de trouver un modèle permettant de prédire **les émissions de CO2 et la consommation totale d’énergie de bâtiments non destinés à l'habitation.**\n",
    "\n",
    "Pour cela nous disposons des données de la ville de Seattle pour les années 2015 et 2016. Ces données sont à récupérer sur le site kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie III : Data modeling\n",
    "\n",
    "Ce notebook a pour but de présenter le travail effectué sur la modélisation.\n",
    "\n",
    "Nous commencerons par séparer notre jeu de données en deux parties distinctes:\n",
    "- Le **training set**, qui va permettre d'entrainer les différents modèles;\n",
    "- Le **testing set**, qui permettra de déterminer la performance du modèle finale.\n",
    "\n",
    "Pour ce faire, la méthode `train_test_split()` de la classe *sklearn.model_selection* sera utilisé en réservant 20% des données pour le jeu de test.\n",
    "\n",
    "Puis les modèles les plus courants seront entraînés et comparés afin de conserver les plus prometteurs. Au préalable, *une recherche par quadrillage* sera effectuée pour automatiser le choix des *hyperparamètres*, et les variables les plus pertinentes seront sélectionnées par RFE (Recursive Feature Elimination).\n",
    "\n",
    "Après sélection des modèles les plus performants, nous affinerons encore les hyperparamètres à l'aide d'une *recherche aléatoire* cette fois ci, et nous en profiterons pour tester la pertinence de la variable *EnergyStarScore*.\n",
    "\n",
    "Nous analyserons enfin les erreurs des modèles afin de déterminer s'il est pertinent d'utiliser une *méthode d'ensemble*, ie. combiner plusieurs modèles pour construire un modèle plus performant.\n",
    "\n",
    "Le modèle final obtenu, nous pourrons évaluer sa performance à l'aide du jeu de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-11T18:30:55.822332Z",
     "start_time": "2020-06-11T18:30:54.608352Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import des librairies usuelles\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-11T18:30:55.837269Z",
     "start_time": "2020-06-11T18:30:55.824323Z"
    }
   },
   "outputs": [],
   "source": [
    "# Change some default parameters of matplotlib using seaborn\n",
    "plt.rcParams.update(plt.rcParamsDefault)\n",
    "plt.rcParams.update({'axes.titleweight': 'bold'})\n",
    "sns.set(style='ticks')\n",
    "current_palette = sns.color_palette('RdBu')\n",
    "sns.set_palette(current_palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-11T18:30:55.914939Z",
     "start_time": "2020-06-11T18:30:55.839261Z"
    }
   },
   "outputs": [],
   "source": [
    "# import data\n",
    "data = (pd.read_csv('data/data_tr.csv')\n",
    "          .set_index('OSEBuildingID')\n",
    "          .drop(columns='ENERGYSTARScore'))\n",
    "data_ess = (pd.read_csv('data/data_tr.csv')\n",
    "              .set_index('OSEBuildingID')\n",
    "              .dropna(subset=['ENERGYSTARScore']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Modéliser-la-consommation-totale-d’énergie\" data-toc-modified-id=\"Modéliser-la-consommation-totale-d’énergie-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Modéliser la consommation totale d’énergie</a></span><ul class=\"toc-item\"><li><span><a href=\"#Créer-un-jeu-de-test\" data-toc-modified-id=\"Créer-un-jeu-de-test-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Créer un jeu de test</a></span></li><li><span><a href=\"#Comparaison-des-modèles\" data-toc-modified-id=\"Comparaison-des-modèles-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Comparaison des modèles</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modéliser la consommation totale d’énergie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour pouvoir modéliser la consommation totale en énergie il faut au préalable déterminer quelle sera notra valeur cible. Sous nous avons quatre variables potentielles :\n",
    "- SiteEnergyUse(kBtu)\n",
    "- SiteEnergyUseWN(kBtu)\n",
    "- SiteEnergyUse(kBtu)_log\n",
    "- SiteEnergyUseWN(kBtu)_log\n",
    "\n",
    "Nous avons vu lors de l'ingénierie des variable qu'il était préférable de prendre la version log pour avoir une distribution se rapprochant d'une distribution normale. On peut donc déjà écarter les deux premières.\n",
    "\n",
    "Se pose ensuite la question de savoir s'il est préférable de garder la version normalisée ou non normalisée. Pour rappel, la version normalisée et la consommation corrigée en prenant comme référence la température des trentes dernières années. Alors que la version normalisée est la consommation moyenne sur les années 2015 et 2016. Dans le contexte de réchauffement climatique, il est fort à parier que la températures des prochaines années sera plus proche de celles de 2015 et 2016 que de la température des trentes dernières années.\n",
    "\n",
    "Nous prendrons donc la version non normalisée **SiteEnergyUse(kBtu)_log**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Créer un jeu de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-11T18:30:56.404382Z",
     "start_time": "2020-06-11T18:30:55.916932Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data.iloc[:, :-6].values\n",
    "y = data.loc[:, 'SiteEnergyUse(kBtu)_log'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le paramètre *random_state* permet de définir *le germe* (seed) du générateur de nombre aléatoires, afin qu'il génère toujours la même suite d'indices pseudo-aléatoires."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparaison des modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour comparer les résultats obtenus avec les algorithmes de regression les plus courants (voir liste ci-dessous), nous utiliserons la librairie *Scikit-Learn* ainsi que la librairie *XGBoost*.\n",
    "- Régression Ridge\n",
    "- Régression Lasso\n",
    "- Elastic Net\n",
    "- Regression SVM\n",
    "- Arbre de décision\n",
    "- Forêt aléatoire\n",
    "- Gradient Boosting\n",
    "- XG Boost\n",
    "- Perceptron\n",
    "\n",
    "Nous utiliserons comme mesure de performance la RMSE par validation croisée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-11T18:30:56.425293Z",
     "start_time": "2020-06-11T18:30:56.408366Z"
    }
   },
   "outputs": [],
   "source": [
    "def linreg_hparams(X, y, estimator, elastic_net=False):\n",
    "    \"\"\" Automated Selection of the hyparameters for linear regression\n",
    "    The selection is based on grid search.\n",
    "    -----------\n",
    "    Parameters:\n",
    "    X: Array\n",
    "        the array object holding data\n",
    "    y: Array\n",
    "        the target\n",
    "    estimator: estimator object\n",
    "        the linear model to be improved\n",
    "    elastic_net: Bool\n",
    "        if linear regression with combined L1 and L2 priors as regularizer\n",
    "    -----------\n",
    "    Return:\n",
    "        estimator\n",
    "    \"\"\"\n",
    "    if elastic_net:\n",
    "        param_grid = [{'alpha': np.logspace(-1, 3, 5),\n",
    "                       'l1_ratio': np.linspace(0.1, 0.9, 9)}]\n",
    "        grid_search = GridSearchCV(estimator, param_grid, cv=5,\n",
    "                                   scoring='neg_mean_squared_error')\n",
    "        grid_search.fit(X, y)\n",
    "        p_a = np.log10(grid_search.best_params_['alpha'])\n",
    "        estimator = grid_search.best_estimator_\n",
    "        param_grid = [{'alpha': np.logspace(p_a-0.3, p_a+0.7, 10)}]\n",
    "        grid_search = GridSearchCV(estimator, param_grid, cv=5,\n",
    "                               scoring='neg_mean_squared_error')\n",
    "        grid_search.fit(X, y)\n",
    "    else:\n",
    "        param_grid = [{'alpha': np.logspace(-1, 3, 5)}]\n",
    "        grid_search = GridSearchCV(estimator, param_grid, cv=5,\n",
    "                                   scoring='neg_mean_squared_error')\n",
    "        grid_search.fit(X, y)\n",
    "        p_a = np.log10(grid_search.best_params_['alpha'])\n",
    "        param_grid = [{'alpha': np.logspace(p_a-0.3, p_a+0.7, 10)}]\n",
    "        grid_search = GridSearchCV(estimator, param_grid, cv=5,\n",
    "                               scoring='neg_mean_squared_error')\n",
    "        grid_search.fit(X, y)\n",
    "    model = grid_search.best_estimator_\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-11T18:30:57.991249Z",
     "start_time": "2020-06-11T18:30:56.428794Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "\n",
    "ridge = linreg_hparams(X, y, Ridge())\n",
    "lasso = linreg_hparams(X, y, Lasso())\n",
    "elastic_net = linreg_hparams(X, y, ElasticNet(), elastic_net=True)\n",
    "models = [ridge,\n",
    "          lasso,\n",
    "          elastic_net]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-11T18:30:58.001207Z",
     "start_time": "2020-06-11T18:30:57.993241Z"
    }
   },
   "outputs": [],
   "source": [
    "def compare_models(X, y, estimators):\n",
    "    \"\"\" Fonction to compare the RMSE get with the\n",
    "    most common Machine Learning Regressors.\n",
    "    -----------\n",
    "    Parameters:\n",
    "    X: Array\n",
    "        the array object holding data\n",
    "    y: Array\n",
    "        the target\n",
    "    estimators: list\n",
    "        List of estimators to be compared\n",
    "    -----------\n",
    "    Return:\n",
    "        DataFrame\n",
    "    \"\"\"\n",
    "    # Train models\n",
    "    scores = []\n",
    "    names = []\n",
    "    std_rmse = []\n",
    "    for m in models:\n",
    "        m.fit(X, y)\n",
    "        m_scores = cross_val_score(m,X, y,\n",
    "                                   scoring=\"neg_mean_squared_error\",\n",
    "                                   cv=10)\n",
    "        m_scores = np.sqrt(-m_scores)\n",
    "        m_names = type(m).__name__\n",
    "        scores.append(m_scores.mean())\n",
    "        std_rmse.append(m_scores.std())\n",
    "        names.append(m_names)\n",
    "    # Create the DataFrame\n",
    "    df = pd.DataFrame({'RMSE_mean': scores, 'RMSE_std': std_rmse}, index=names)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-11T18:30:58.182438Z",
     "start_time": "2020-06-11T18:30:58.004195Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE_mean</th>\n",
       "      <th>RMSE_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.900369</td>\n",
       "      <td>0.151509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.932346</td>\n",
       "      <td>0.327280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>0.905065</td>\n",
       "      <td>0.195328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            RMSE_mean  RMSE_std\n",
       "Ridge        0.900369  0.151509\n",
       "Lasso        0.932346  0.327280\n",
       "ElasticNet   0.905065  0.195328"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "df = compare_models(X, y, models)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-11T18:30:58.252144Z",
     "start_time": "2020-06-11T18:30:58.185426Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "#from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def compare_models(X, y):\n",
    "    \"\"\" Fonction to compare the RMSE get with the\n",
    "    most common Machine Learning Regressors.\n",
    "    -----------\n",
    "    Parameters:\n",
    "    X: Array\n",
    "        the array object holding data\n",
    "    y: Array\n",
    "        the target\n",
    "    -----------\n",
    "    Return:\n",
    "        DataFrame\n",
    "    \"\"\"\n",
    "    # Create models\n",
    "    ridge = Ridge()\n",
    "    lasso = Lasso()\n",
    "    elastic_net = ElasticNet()\n",
    "    svm_reg = LinearSVR()\n",
    "    tree_reg = DecisionTreeRegressor()\n",
    "    forest_reg = RandomForestRegressor()\n",
    "    gbrt = GradientBoostingRegressor()\n",
    "    # xgbr = XGBRegressor()\n",
    "    perceptron = Perceptron()\n",
    "    models = [ridge,\n",
    "              lasso,\n",
    "              elastic_net,\n",
    "              #svm_reg,\n",
    "              tree_reg,\n",
    "              forest_reg,\n",
    "              gbrt]\n",
    "    # Train models\n",
    "    scores = []\n",
    "    names = []\n",
    "    std_rmse = []\n",
    "    for m in models:\n",
    "        m.fit(X, y)\n",
    "        m_scores = cross_val_score(m,X, y,\n",
    "                                   scoring=\"neg_mean_squared_error\",\n",
    "                                   cv=10)\n",
    "        m_scores = np.sqrt(-m_scores)\n",
    "        m_names = type(m).__name__\n",
    "        scores.append(m_scores.mean())\n",
    "        std_rmse.append(m_scores.std())\n",
    "        names.append(m_names)\n",
    "    # Create the DataFrame\n",
    "    df = pd.DataFrame({'RMSE_mean': scores, 'RMSE_std': std_rmse}, index=names)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-11T18:31:03.790887Z",
     "start_time": "2020-06-11T18:30:58.254135Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pe.ragettli\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE_mean</th>\n",
       "      <th>RMSE_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.976681</td>\n",
       "      <td>0.478513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Lasso</td>\n",
       "      <td>1.315544</td>\n",
       "      <td>0.171342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>1.285348</td>\n",
       "      <td>0.177976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>0.447522</td>\n",
       "      <td>0.101716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.306740</td>\n",
       "      <td>0.081940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>0.209423</td>\n",
       "      <td>0.059488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           RMSE_mean  RMSE_std\n",
       "Ridge                       0.976681  0.478513\n",
       "Lasso                       1.315544  0.171342\n",
       "ElasticNet                  1.285348  0.177976\n",
       "DecisionTreeRegressor       0.447522  0.101716\n",
       "RandomForestRegressor       0.306740  0.081940\n",
       "GradientBoostingRegressor   0.209423  0.059488"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comp =  compare_models(X, y)\n",
    "df_comp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": "1",
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "254px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
